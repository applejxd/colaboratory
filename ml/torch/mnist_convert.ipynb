{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2oys+5Ghyoj4Jxrj8HtId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/applejxd/colaboratory/blob/master/ml/torch/mnist_convert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST 認識モデルを PyTorch で構築して変換"
      ],
      "metadata": {
        "id": "CdtJfRLDk99f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[公式サンプル](https://github.com/pytorch/examples/blob/main/mnist/main.py)をベースに実装"
      ],
      "metadata": {
        "id": "npgWlwYymD-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 事前確認"
      ],
      "metadata": {
        "id": "JBP-5GkT5wJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "バージョンチェック"
      ],
      "metadata": {
        "id": "CtqNKLpKlCMk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IE9CixSjhB2",
        "outputId": "cf7b8d6c-2465-4afe-9e31-dff7f054b20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.__version__=2.1.0+cu118\n",
            "torch.cuda.is_available()=True\n",
            "\n",
            "torch.cuda.device_count()=True\n",
            "torch.cuda.current_device()=True\n",
            "torch.cuda.device(0)=<torch.cuda.device object at 0x7850f5862080>\n",
            "\n",
            "torch.cuda.get_device_name(0)=Tesla T4\n",
            "torch.cuda.get_device_capability()=(7, 5)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"torch.__version__={torch.__version__}\")\n",
        "print(f\"torch.cuda.is_available()={torch.cuda.is_available()}\\n\")\n",
        "\n",
        "print(f\"torch.cuda.device_count()={torch.cuda.is_available()}\")\n",
        "print(f\"torch.cuda.current_device()={torch.cuda.is_available()}\")\n",
        "print(f\"torch.cuda.device(0)={torch.cuda.device(0)}\\n\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"torch.cuda.get_device_name(0)={torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"torch.cuda.get_device_capability()={torch.cuda.get_device_capability()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[使用するデバイスを確認](https://colab.research.google.com/notebooks/pro.ipynb#scrollTo=23TOba33L4qf)"
      ],
      "metadata": {
        "id": "ONL0tIoB2cKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ZUyESmq92ezR",
        "outputId": "13f9a498-b145-476a-de50-39c4e81cb8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 12 15:55:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "seed の固定。deterministic は処理低下を起こすため注意。"
      ],
      "metadata": {
        "id": "SxIPUjmRa_xf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def torch_fix_seed(seed=42):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "    # torch.use_deterministic_algorithms = True\n",
        "\n",
        "torch_fix_seed()"
      ],
      "metadata": {
        "id": "TgEyv5e8bBHb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorboard の用意"
      ],
      "metadata": {
        "id": "EdSFLrhTN6NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "-nvReMPJN_sp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセットの用意"
      ],
      "metadata": {
        "id": "Ym1ivrpfaxui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの読み込み"
      ],
      "metadata": {
        "id": "rkZ6Xe7U71Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "mean, scale = 0.1307, 0.3081\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((mean,), (scale,))\n",
        "])\n",
        "\n",
        "dataset1 = datasets.MNIST(\n",
        "    '../data', train=True, download=True, transform=transform)\n",
        "dataset2 = datasets.MNIST(\n",
        "    '../data', train=False, transform=transform)"
      ],
      "metadata": {
        "id": "_KL0PVezmU2u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データの可視化"
      ],
      "metadata": {
        "id": "eiAhcoG978N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset1_data = dataset1.data.numpy()\n",
        "dataset1_targets = dataset1.targets.numpy()\n",
        "\n",
        "print(f\"dataset1_targets[0]={dataset1_targets[0]}\")\n",
        "print(f\"dataset1_data.shape={dataset1_data.shape}\")\n",
        "img = dataset1_data[0]\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "DYxJOf2imuzr",
        "outputId": "4d9a2542-f749-4650-d643-1a6d30d63277"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset1_targets[0]=5\n",
            "dataset1_data.shape=(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x784fb1441300>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データローダの作成。\n",
        "[高速化のためのオプション](https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587)を設定。"
      ],
      "metadata": {
        "id": "m7-UvLMc9Hv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_kwargs = {\n",
        "    'num_workers': 2,\n",
        "    'pin_memory': True,\n",
        "    'shuffle': True\n",
        "}\n",
        "\n",
        "train_batch_size, test_batch_size = 64, 1000\n",
        "train_kwargs = {'batch_size': train_batch_size}\n",
        "test_kwargs = {'batch_size': test_batch_size}\n",
        "\n",
        "train_kwargs.update(cuda_kwargs)\n",
        "test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
      ],
      "metadata": {
        "id": "YKlXkbQJm7Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル作成"
      ],
      "metadata": {
        "id": "2oPLSDAxavRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデル定義"
      ],
      "metadata": {
        "id": "MlXEO5HJ9YxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "cY1Nb4iy9ZcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルのインスタンスを作成"
      ],
      "metadata": {
        "id": "T9vQjCdn_5Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Use device={device_str}\")\n",
        "device = torch.device(device_str)\n",
        "\n",
        "model = Net().to(device)"
      ],
      "metadata": {
        "id": "IRJLCiFN9nxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "単一データで推論する関数を定義。推論前に `model.eval()` が必要なことに注意。"
      ],
      "metadata": {
        "id": "5GXkFosubTPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_inference(model, idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...].to(device)\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    # use inference mode\n",
        "    # (otherwise 32 batch size needed)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = model(img)\n",
        "\n",
        "    # get highest probability\n",
        "    inference = probs.argmax(dim=1, keepdim=True)[0, 0]\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")"
      ],
      "metadata": {
        "id": "PQ-w2ZtdaON7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際に推論。未学習なので不正解。"
      ],
      "metadata": {
        "id": "zOSkNEs5bW5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_inference(model, idx=0)"
      ],
      "metadata": {
        "id": "e4ElM2MPbZnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "7oAnlffUasZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最適化手法を定義"
      ],
      "metadata": {
        "id": "na1sdxMgAIsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "lr = 1.0\n",
        "gamma = 0.7\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
      ],
      "metadata": {
        "id": "XpbCtU8E_nQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習方法を定義"
      ],
      "metadata": {
        "id": "rpvHlmpwMAZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval = 10\n",
        "dry_run = False\n",
        "amp_dtype = torch.float16 if device_str == \"cuda\" else torch.bfloat16\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    # AMP: Automatic Mixed Precision\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # data transfer\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # AMP: Automatic Mixed Precision\n",
        "        with torch.amp.autocast(device_str, dtype=amp_dtype):\n",
        "            # inference\n",
        "            output = model(data)\n",
        "            # nll = negative log likelihood loss\n",
        "            loss = F.nll_loss(output, target)\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "\n",
        "        # back propagation\n",
        "        scaler.scale(loss).backward()\n",
        "        # gradient decent\n",
        "        scaler.step(optimizer)\n",
        "        # update scale\n",
        "        scaler.update()\n",
        "\n",
        "#        if batch_idx % log_interval != 0:\n",
        "#            continue\n",
        "\n",
        "#        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "#            100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "#        if dry_run:\n",
        "#            break"
      ],
      "metadata": {
        "id": "xtZvqbdyAGzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論・バリデーション"
      ],
      "metadata": {
        "id": "IENi3VgUbeGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    # print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.3f}%)\")"
      ],
      "metadata": {
        "id": "_l9bjrQzN8mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習を実行"
      ],
      "metadata": {
        "id": "EzJeYxj9bjzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 14\n",
        "for epoch in tqdm(range(1, epochs + 1)):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "writer.flush()"
      ],
      "metadata": {
        "id": "9DZzjZdgONRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensorboard の起動。\n",
        "Chrome との相性が悪いため [Tips](https://github.com/googlecolab/colabtools/issues/3990#issuecomment-1782676249) を利用。"
      ],
      "metadata": {
        "id": "tz4ViDSYQ3Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%load_ext tensorboard\n",
        "# Start tensorboard\n",
        "# Please ignore the error page in the output and go to the next cell\n",
        "%tensorboard --logdir ./logs --host=127.0.0.1 --port=6006 --load_fast=false"
      ],
      "metadata": {
        "id": "ybxiNsJ7OHo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "外部リンクから Tensorboard にアクセス"
      ],
      "metadata": {
        "id": "fZ7YMD2URQYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access tensorboard via colab's proxy\n",
        "# Click the link that appears in the output\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(6006, path=\"\")"
      ],
      "metadata": {
        "id": "flivFxYbQYnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルの保存。対象は元のモデル。"
      ],
      "metadata": {
        "id": "QiR1m3drcMg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
      ],
      "metadata": {
        "id": "S9vmJLdocLDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論"
      ],
      "metadata": {
        "id": "eRmwlK3uapKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "保存したモデルのロード"
      ],
      "metadata": {
        "id": "Wh4KFVrPcner"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('mnist_cnn.pth'))"
      ],
      "metadata": {
        "id": "a-RXTXNxcp6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論を実施"
      ],
      "metadata": {
        "id": "TApM_4MDbSOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_inference(model, idx=0)"
      ],
      "metadata": {
        "id": "B373mx2RSyFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 別形式への変換"
      ],
      "metadata": {
        "id": "ejZYlLQ6jfLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ここ](https://qiita.com/hirune924/items/06520f44927b0844a86c)を参照"
      ],
      "metadata": {
        "id": "KiZ1y7YkjitP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchScript"
      ],
      "metadata": {
        "id": "KBHSLPB3jPg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Scripting による変換](https://rarejob-tech-dept.hatenablog.com/entry/2022/07/29/190000)"
      ],
      "metadata": {
        "id": "TKOcPheElvmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_model = torch.jit.script(model)\n",
        "script_model.save(\"mnist_cnn_script.pth\")\n",
        "script_model = torch.jit.load(\"mnist_cnn_script.pth\")\n",
        "single_inference(script_model, idx=0)"
      ],
      "metadata": {
        "id": "DYu2pXPYhF1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ONNX"
      ],
      "metadata": {
        "id": "Fx8UoUVTsZtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ここを参照](https://colab.research.google.com/drive/13CxIsi4CfV-Cn40B9xnAfka9NqzSjk84?usp=sharing)"
      ],
      "metadata": {
        "id": "_pJVJcxksbxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.onnx の利用に onnx ライブラリが必要。\n",
        "GPUでの実行は onnxruntime-gpu をインストール。"
      ],
      "metadata": {
        "id": "YKNenC_k5Q1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install onnx\n",
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "n2Hqz2o4hGju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ダミーの入力を利用して変換・出力"
      ],
      "metadata": {
        "id": "KRtnVJlNtlvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dummy_input(model, idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...].to(device)\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    return img\n",
        "\n",
        "dummy_input = get_dummy_input(model, idx=0)\n",
        "torch.onnx.export(model, dummy_input, \"mnist_cnn.onnx\", verbose=True,\n",
        "                  # for ONNX -> TensorFlow\n",
        "                  input_names=['input'], output_names=['output'])"
      ],
      "metadata": {
        "id": "uwfa7SS5sg0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ロードしてモデルの確認](https://qiita.com/studio_haneya/items/be9bc7c56af44b7c1e0a#4-2-%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E6%BA%96%E5%82%99)"
      ],
      "metadata": {
        "id": "IuLxXzyWv0oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"mnist_cnn.onnx\")\n",
        "\n",
        "onnx.checker.check_model(onnx_model)\n",
        "print(onnx.helper.printable_graph(onnx_model.graph))"
      ],
      "metadata": {
        "id": "kSk7FQ_BvM_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "セッション作成"
      ],
      "metadata": {
        "id": "k_ZJJz7Yz7Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "sess = onnxruntime.InferenceSession(\n",
        "    \"mnist_cnn.onnx\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])"
      ],
      "metadata": {
        "id": "nocNX58_tGnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[推論を実施](https://colab.research.google.com/github/YutaroOgawa/pytorch_tutorials_jp/blob/main/notebook/5_Deployment/5_4_super_resolution_with_onnxruntime_jp.ipynb#scrollTo=MRcd4bt0cnAt)"
      ],
      "metadata": {
        "id": "8CXz2aWi1Z5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "def onnx_single_inference(idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...]\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    img = to_numpy(img)\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    ort_inputs = {sess.get_inputs()[0].name: img}\n",
        "    probs = sess.run(None, ort_inputs)\n",
        "\n",
        "    # get highest probability\n",
        "    inference = np.argmax(np.array(probs))\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")\n",
        "\n",
        "onnx_single_inference(idx=0)"
      ],
      "metadata": {
        "id": "2SYQwohf0FvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow"
      ],
      "metadata": {
        "id": "CyOduinD13_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[onnx-tensorflow](https://github.com/onnx/onnx-tensorflow) をインストール"
      ],
      "metadata": {
        "id": "pK5RTtXi4Csc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install onnx-tf"
      ],
      "metadata": {
        "id": "RwZt-XYV1doo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ここ](https://colab.research.google.com/drive/13CxIsi4CfV-Cn40B9xnAfka9NqzSjk84?usp=sharing#scrollTo=_EH_Sd64nE9p)を参考にONNXのモデルを読み込み。\n",
        "[ここ](https://github.com/onnx/onnx-tensorflow/blob/main/doc/API.md)からTFのモデルへ変換。"
      ],
      "metadata": {
        "id": "M8jYCj6r4GAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnx_tf.backend import prepare\n",
        "\n",
        "# onnx_tf.backend_rep.TensorflowRep\n",
        "tf_rep_model = prepare(onnx_model)\n",
        "# save TF model\n",
        "tf_rep_model.export_graph(\"mnist_cnn_tf\")"
      ],
      "metadata": {
        "id": "gHHVyzgt2Kyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorflowRep のまま推論"
      ],
      "metadata": {
        "id": "L37N0dYCBEMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_rep_single_inference(idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...]\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    img = to_numpy(img)\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    probs = tf_rep_model.run(img)\n",
        "\n",
        "    # get highest probability\n",
        "    inference = np.argmax(np.array(probs))\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")\n",
        "\n",
        "tf_rep_single_inference(idx=0)"
      ],
      "metadata": {
        "id": "M1iPjQyb4SWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TenforFlow のモデルと推論機能を読み込み"
      ],
      "metadata": {
        "id": "cra8U_XEBHI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf_model = tf.saved_model.load(\"mnist_cnn_tf\")\n",
        "infer = tf_model.signatures[\"serving_default\"]"
      ],
      "metadata": {
        "id": "Pu7nxHiU6x_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "出力形式を確認しておく"
      ],
      "metadata": {
        "id": "1NU7SytMBKt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_infer = tf_model.signatures[\"serving_default\"]\n",
        "print(tf_infer.structured_outputs)"
      ],
      "metadata": {
        "id": "ItYHXueyAmU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論を実施"
      ],
      "metadata": {
        "id": "jw56NMOzBMtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_single_inference(idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...]\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    img = to_numpy(img)\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    output_name = tf_infer.structured_outputs[\"output\"].name\n",
        "    probs = tf_infer(tf.constant(img))[output_name]\n",
        "\n",
        "    # get highest probability\n",
        "    inference = np.argmax(np.array(probs))\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")\n",
        "\n",
        "tf_single_inference(idx=0)"
      ],
      "metadata": {
        "id": "1Psfsijf92Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFLite"
      ],
      "metadata": {
        "id": "mXc3z3D3Bchb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"mnist_cnn_tf\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"mnist_cnn.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "O4iaCc5XAaFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ここ](https://qiita.com/yohachi/items/434f0da356161e82c242)を参考にモデルの読み込み"
      ],
      "metadata": {
        "id": "2qiV86XhCRxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TFLiteモデルの読み込み\n",
        "tfl_model = tf.lite.Interpreter(model_path=\"mnist_cnn.tflite\")\n",
        "# メモリ確保。これはモデル読み込み直後に必須\n",
        "tfl_model.allocate_tensors()"
      ],
      "metadata": {
        "id": "RAu3L3OPBjjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "入力形式について確認"
      ],
      "metadata": {
        "id": "h3IoMpHGDIke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfl_model.get_input_details()"
      ],
      "metadata": {
        "id": "sOZFGD_LC4GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tfl_single_inference(idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...]\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    img = to_numpy(img)\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    # indexにテンソルデータのポインタをセット\n",
        "    input_details = tfl_model.get_input_details()\n",
        "    tfl_model.set_tensor(input_details[0]['index'], img)\n",
        "\n",
        "    # 推論実行\n",
        "    tfl_model.invoke()\n",
        "\n",
        "    # 推論結果は、output_detailsのindexに保存されている\n",
        "    output_details = tfl_model.get_output_details()\n",
        "    probs = tfl_model.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # get highest probability\n",
        "    inference = np.argmax(np.array(probs))\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")\n",
        "\n",
        "\n",
        "tfl_single_inference(idx=0)"
      ],
      "metadata": {
        "id": "qyLvtRw2CxPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenVINO"
      ],
      "metadata": {
        "id": "TDd6cTpkHJWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openvino\n",
        "!pip install openvino-dev"
      ],
      "metadata": {
        "id": "7tp0LPu1EtQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch から OpenVINO のモデルへ変換"
      ],
      "metadata": {
        "id": "bfqMACjlLpTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openvino.tools.mo import convert_model\n",
        "\n",
        "ov_model = convert_model(model, example_input=dummy_input)"
      ],
      "metadata": {
        "id": "yUAZ-EE6HMTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openvino as ov\n",
        "import ipywidgets as widgets\n",
        "\n",
        "core = ov.Core()\n",
        "device = widgets.Dropdown(\n",
        "    options=core.available_devices + [\"AUTO\"],\n",
        "    value='AUTO',\n",
        "    description='Device:',\n",
        "    disabled=False,\n",
        ")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "quxFX4uBL7t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "コンパイルを実施"
      ],
      "metadata": {
        "id": "l2tYXJJBNbQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ov_compiled_model = core.compile_model(model=ov_model, device_name=device.value)"
      ],
      "metadata": {
        "id": "Vm4hk6tTMtLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "推論"
      ],
      "metadata": {
        "id": "pJc5MrQINcyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ov_single_inference(idx):\n",
        "    # slice only 1 data\n",
        "    img = dataset1.data[[idx], ...]\n",
        "    # add channel axis (size 1)\n",
        "    img = img[:, None, ...]\n",
        "    # normalization\n",
        "    img = (img - mean) / scale\n",
        "    img = to_numpy(img)\n",
        "\n",
        "    print(f\"input data shape = {img.shape}\")\n",
        "\n",
        "    probs = ov_compiled_model([img])[0]\n",
        "    print(probs)\n",
        "\n",
        "    # get highest probability\n",
        "    inference = np.argmax(np.array(probs))\n",
        "    answer = dataset1.targets[idx]\n",
        "\n",
        "    print(f\"inference={inference}\")\n",
        "    print(f\"answer={answer}\")\n",
        "\n",
        "ov_single_inference(idx=0)"
      ],
      "metadata": {
        "id": "rc0blzroK0tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MyriadX blob for OAK-D camera"
      ],
      "metadata": {
        "id": "PPmqh6e1UorO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install blobconverter"
      ],
      "metadata": {
        "id": "idrlLkB5VUDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ここ](https://docs.luxonis.com/en/latest/pages/model_conversion/)に従って Web API で変換。\n",
        "ローカルのコンパイルが必要な場合は[ここ](https://docs.luxonis.com/en/latest/pages/tutorials/local_convert_openvino/)を参照。"
      ],
      "metadata": {
        "id": "zpBDSIcvWaj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import blobconverter\n",
        "\n",
        "blob_path = blobconverter.from_onnx(\n",
        "    model=\"mnist_cnn.onnx\",\n",
        "    data_type=\"FP16\",\n",
        "    shaves=5,\n",
        "    optimizer_params=[\n",
        "        \"--input_shape=[1,1,28,28]\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "YGsTtImFV09b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob_path"
      ],
      "metadata": {
        "id": "QZcCA1BK4KRB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}